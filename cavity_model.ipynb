{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"from torch.utils.data import Dataset, DataLoader\\nfrom typing import List, Callable\\nimport numpy as np\\nimport torch\\nimport glob\\nimport random\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"from torch.utils.data import Dataset, DataLoader\\nfrom typing import List, Callable\\nimport numpy as np\\nimport torch\\nimport glob\\nimport random\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Callable\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import random\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 4X2U.pdb to data/raw/4X2U.pdb. 1/250.\n",
      "Successfully downloaded 2X96.pdb to data/raw/2X96.pdb. 2/250.\n",
      "Successfully downloaded 4MXD.pdb to data/raw/4MXD.pdb. 3/250.\n",
      "Successfully downloaded 3E9L.pdb to data/raw/3E9L.pdb. 4/250.\n",
      "Successfully downloaded 1UWC.pdb to data/raw/1UWC.pdb. 5/250.\n",
      "Successfully downloaded 4BGU.pdb to data/raw/4BGU.pdb. 6/250.\n",
      "Successfully downloaded 2YSW.pdb to data/raw/2YSW.pdb. 7/250.\n",
      "Successfully downloaded 4OW4.pdb to data/raw/4OW4.pdb. 8/250.\n",
      "Successfully downloaded 2V5E.pdb to data/raw/2V5E.pdb. 9/250.\n",
      "Successfully downloaded 1IXH.pdb to data/raw/1IXH.pdb. 10/250.\n",
      "Successfully downloaded 3ZR9.pdb to data/raw/3ZR9.pdb. 11/250.\n",
      "Successfully downloaded 4O7Q.pdb to data/raw/4O7Q.pdb. 12/250.\n",
      "Successfully downloaded 3OBL.pdb to data/raw/3OBL.pdb. 13/250.\n",
      "Successfully downloaded 2YVP.pdb to data/raw/2YVP.pdb. 14/250.\n",
      "Successfully downloaded 1UNK.pdb to data/raw/1UNK.pdb. 15/250.\n",
      "Successfully downloaded 5B2H.pdb to data/raw/5B2H.pdb. 16/250.\n",
      "Successfully downloaded 5FEN.pdb to data/raw/5FEN.pdb. 17/250.\n",
      "Successfully downloaded 2CN4.pdb to data/raw/2CN4.pdb. 18/250.\n",
      "Successfully downloaded 1LDD.pdb to data/raw/1LDD.pdb. 19/250.\n",
      "Successfully downloaded 2PIA.pdb to data/raw/2PIA.pdb. 20/250.\n",
      "Successfully downloaded 3MX7.pdb to data/raw/3MX7.pdb. 21/250.\n",
      "Successfully downloaded 2XU3.pdb to data/raw/2XU3.pdb. 22/250.\n",
      "Successfully downloaded 4DPB.pdb to data/raw/4DPB.pdb. 23/250.\n",
      "Successfully downloaded 1F47.pdb to data/raw/1F47.pdb. 24/250.\n",
      "Successfully downloaded 3U4Z.pdb to data/raw/3U4Z.pdb. 25/250.\n",
      "Successfully downloaded 1IQQ.pdb to data/raw/1IQQ.pdb. 26/250.\n",
      "Successfully downloaded 4FIV.pdb to data/raw/4FIV.pdb. 27/250.\n",
      "Successfully downloaded 2QSK.pdb to data/raw/2QSK.pdb. 28/250.\n",
      "Successfully downloaded 1QQS.pdb to data/raw/1QQS.pdb. 29/250.\n",
      "Successfully downloaded 1DAB.pdb to data/raw/1DAB.pdb. 30/250.\n",
      "Successfully downloaded 1LXY.pdb to data/raw/1LXY.pdb. 31/250.\n",
      "Successfully downloaded 1Z2U.pdb to data/raw/1Z2U.pdb. 32/250.\n",
      "Successfully downloaded 2HLC.pdb to data/raw/2HLC.pdb. 33/250.\n",
      "Successfully downloaded 1TU7.pdb to data/raw/1TU7.pdb. 34/250.\n",
      "Successfully downloaded 2GDM.pdb to data/raw/2GDM.pdb. 35/250.\n",
      "Successfully downloaded 3RBA.pdb to data/raw/3RBA.pdb. 36/250.\n",
      "Successfully downloaded 1GYX.pdb to data/raw/1GYX.pdb. 37/250.\n",
      "Successfully downloaded 3EF4.pdb to data/raw/3EF4.pdb. 38/250.\n",
      "Successfully downloaded 1HRD.pdb to data/raw/1HRD.pdb. 39/250.\n",
      "Successfully downloaded 1HI9.pdb to data/raw/1HI9.pdb. 40/250.\n",
      "Successfully downloaded 4UPG.pdb to data/raw/4UPG.pdb. 41/250.\n",
      "Successfully downloaded 4ZUR.pdb to data/raw/4ZUR.pdb. 42/250.\n",
      "Successfully downloaded 1CPQ.pdb to data/raw/1CPQ.pdb. 43/250.\n",
      "Successfully downloaded 3AU0.pdb to data/raw/3AU0.pdb. 44/250.\n",
      "Successfully downloaded 3IPJ.pdb to data/raw/3IPJ.pdb. 45/250.\n",
      "Successfully downloaded 4BGV.pdb to data/raw/4BGV.pdb. 46/250.\n",
      "Successfully downloaded 5GSM.pdb to data/raw/5GSM.pdb. 47/250.\n",
      "Successfully downloaded 4RSX.pdb to data/raw/4RSX.pdb. 48/250.\n",
      "Successfully downloaded 1UAS.pdb to data/raw/1UAS.pdb. 49/250.\n",
      "Successfully downloaded 2CB5.pdb to data/raw/2CB5.pdb. 50/250.\n",
      "Successfully downloaded 1NCX.pdb to data/raw/1NCX.pdb. 51/250.\n",
      "Successfully downloaded 1A6M.pdb to data/raw/1A6M.pdb. 52/250.\n",
      "Successfully downloaded 3C8Y.pdb to data/raw/3C8Y.pdb. 53/250.\n",
      "Successfully downloaded 5KH6.pdb to data/raw/5KH6.pdb. 54/250.\n",
      "Successfully downloaded 3AI3.pdb to data/raw/3AI3.pdb. 55/250.\n",
      "Successfully downloaded 4YYP.pdb to data/raw/4YYP.pdb. 56/250.\n",
      "Successfully downloaded 3PX8.pdb to data/raw/3PX8.pdb. 57/250.\n",
      "Successfully downloaded 2Q35.pdb to data/raw/2Q35.pdb. 58/250.\n",
      "Successfully downloaded 4YHE.pdb to data/raw/4YHE.pdb. 59/250.\n",
      "Successfully downloaded 1QLM.pdb to data/raw/1QLM.pdb. 60/250.\n",
      "Successfully downloaded 3IE2.pdb to data/raw/3IE2.pdb. 61/250.\n",
      "Successfully downloaded 2QA0.pdb to data/raw/2QA0.pdb. 62/250.\n",
      "Successfully downloaded 3GA3.pdb to data/raw/3GA3.pdb. 63/250.\n",
      "Successfully downloaded 4XDO.pdb to data/raw/4XDO.pdb. 64/250.\n",
      "Successfully downloaded 1CQJ.pdb to data/raw/1CQJ.pdb. 65/250.\n",
      "Successfully downloaded 3AG6.pdb to data/raw/3AG6.pdb. 66/250.\n",
      "Successfully downloaded 4ICQ.pdb to data/raw/4ICQ.pdb. 67/250.\n",
      "Successfully downloaded 4QU2.pdb to data/raw/4QU2.pdb. 68/250.\n",
      "Successfully downloaded 1OCY.pdb to data/raw/1OCY.pdb. 69/250.\n",
      "Successfully downloaded 1M08.pdb to data/raw/1M08.pdb. 70/250.\n",
      "Successfully downloaded 1ZH1.pdb to data/raw/1ZH1.pdb. 71/250.\n",
      "Successfully downloaded 1DXG.pdb to data/raw/1DXG.pdb. 72/250.\n",
      "Successfully downloaded 4P08.pdb to data/raw/4P08.pdb. 73/250.\n",
      "Successfully downloaded 1EKM.pdb to data/raw/1EKM.pdb. 74/250.\n",
      "Successfully downloaded 2D3Y.pdb to data/raw/2D3Y.pdb. 75/250.\n",
      "Successfully downloaded 2CE8.pdb to data/raw/2CE8.pdb. 76/250.\n",
      "Successfully downloaded 5ED7.pdb to data/raw/5ED7.pdb. 77/250.\n",
      "Successfully downloaded 1RMD.pdb to data/raw/1RMD.pdb. 78/250.\n",
      "Successfully downloaded 3W7B.pdb to data/raw/3W7B.pdb. 79/250.\n",
      "Successfully downloaded 1DCI.pdb to data/raw/1DCI.pdb. 80/250.\n",
      "Successfully downloaded 1L7A.pdb to data/raw/1L7A.pdb. 81/250.\n",
      "Successfully downloaded 3S2E.pdb to data/raw/3S2E.pdb. 82/250.\n",
      "Successfully downloaded 4LBS.pdb to data/raw/4LBS.pdb. 83/250.\n",
      "Successfully downloaded 4WMH.pdb to data/raw/4WMH.pdb. 84/250.\n",
      "Successfully downloaded 2PA1.pdb to data/raw/2PA1.pdb. 85/250.\n",
      "Successfully downloaded 2ERL.pdb to data/raw/2ERL.pdb. 86/250.\n",
      "Successfully downloaded 4ERC.pdb to data/raw/4ERC.pdb. 87/250.\n",
      "Successfully downloaded 1IJB.pdb to data/raw/1IJB.pdb. 88/250.\n",
      "Successfully downloaded 1LK5.pdb to data/raw/1LK5.pdb. 89/250.\n",
      "Successfully downloaded 4DWQ.pdb to data/raw/4DWQ.pdb. 90/250.\n",
      "Successfully downloaded 3ODV.pdb to data/raw/3ODV.pdb. 91/250.\n",
      "Successfully downloaded 4E5R.pdb to data/raw/4E5R.pdb. 92/250.\n",
      "Successfully downloaded 4XRF.pdb to data/raw/4XRF.pdb. 93/250.\n",
      "Successfully downloaded 1QST.pdb to data/raw/1QST.pdb. 94/250.\n",
      "Successfully downloaded 2OF3.pdb to data/raw/2OF3.pdb. 95/250.\n",
      "Successfully downloaded 3K1R.pdb to data/raw/3K1R.pdb. 96/250.\n",
      "Successfully downloaded 3B02.pdb to data/raw/3B02.pdb. 97/250.\n",
      "Successfully downloaded 1ALY.pdb to data/raw/1ALY.pdb. 98/250.\n",
      "Successfully downloaded 2IFV.pdb to data/raw/2IFV.pdb. 99/250.\n",
      "Successfully downloaded 4KNU.pdb to data/raw/4KNU.pdb. 100/250.\n",
      "Successfully downloaded 3FBL.pdb to data/raw/3FBL.pdb. 101/250.\n",
      "Successfully downloaded 2WKK.pdb to data/raw/2WKK.pdb. 102/250.\n",
      "Successfully downloaded 1GNT.pdb to data/raw/1GNT.pdb. 103/250.\n",
      "Successfully downloaded 1I4J.pdb to data/raw/1I4J.pdb. 104/250.\n",
      "Successfully downloaded 1D2C.pdb to data/raw/1D2C.pdb. 105/250.\n",
      "Successfully downloaded 1H16.pdb to data/raw/1H16.pdb. 106/250.\n",
      "Successfully downloaded 1DQZ.pdb to data/raw/1DQZ.pdb. 107/250.\n",
      "Successfully downloaded 4FD2.pdb to data/raw/4FD2.pdb. 108/250.\n",
      "Successfully downloaded 3G7E.pdb to data/raw/3G7E.pdb. 109/250.\n",
      "Successfully downloaded 5MB4.pdb to data/raw/5MB4.pdb. 110/250.\n",
      "Successfully downloaded 2IVG.pdb to data/raw/2IVG.pdb. 111/250.\n",
      "Successfully downloaded 1BXY.pdb to data/raw/1BXY.pdb. 112/250.\n",
      "Successfully downloaded 3RMU.pdb to data/raw/3RMU.pdb. 113/250.\n",
      "Successfully downloaded 2D48.pdb to data/raw/2D48.pdb. 114/250.\n",
      "Successfully downloaded 2BNU.pdb to data/raw/2BNU.pdb. 115/250.\n",
      "Successfully downloaded 1QQM.pdb to data/raw/1QQM.pdb. 116/250.\n",
      "Successfully downloaded 1CN3.pdb to data/raw/1CN3.pdb. 117/250.\n",
      "Successfully downloaded 5IZW.pdb to data/raw/5IZW.pdb. 118/250.\n",
      "Successfully downloaded 5EYS.pdb to data/raw/5EYS.pdb. 119/250.\n",
      "Successfully downloaded 3E4G.pdb to data/raw/3E4G.pdb. 120/250.\n",
      "Successfully downloaded 2OR2.pdb to data/raw/2OR2.pdb. 121/250.\n",
      "Successfully downloaded 1BU2.pdb to data/raw/1BU2.pdb. 122/250.\n",
      "Successfully downloaded 5MND.pdb to data/raw/5MND.pdb. 123/250.\n",
      "Successfully downloaded 1EI9.pdb to data/raw/1EI9.pdb. 124/250.\n",
      "Successfully downloaded 1KUU.pdb to data/raw/1KUU.pdb. 125/250.\n",
      "Successfully downloaded 5AYE.pdb to data/raw/5AYE.pdb. 126/250.\n",
      "Successfully downloaded 1L2P.pdb to data/raw/1L2P.pdb. 127/250.\n",
      "Successfully downloaded 4O7K.pdb to data/raw/4O7K.pdb. 128/250.\n",
      "Successfully downloaded 1AGJ.pdb to data/raw/1AGJ.pdb. 129/250.\n",
      "Successfully downloaded 1ZZG.pdb to data/raw/1ZZG.pdb. 130/250.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 4UEJ.pdb to data/raw/4UEJ.pdb. 131/250.\n",
      "Successfully downloaded 5HI8.pdb to data/raw/5HI8.pdb. 132/250.\n",
      "Successfully downloaded 1HG0.pdb to data/raw/1HG0.pdb. 133/250.\n",
      "Successfully downloaded 1EX7.pdb to data/raw/1EX7.pdb. 134/250.\n",
      "Successfully downloaded 1V7C.pdb to data/raw/1V7C.pdb. 135/250.\n",
      "Successfully downloaded 1QJ8.pdb to data/raw/1QJ8.pdb. 136/250.\n",
      "Successfully downloaded 2JHF.pdb to data/raw/2JHF.pdb. 137/250.\n",
      "Successfully downloaded 2Z3V.pdb to data/raw/2Z3V.pdb. 138/250.\n",
      "Successfully downloaded 3BL2.pdb to data/raw/3BL2.pdb. 139/250.\n",
      "Successfully downloaded 2OKT.pdb to data/raw/2OKT.pdb. 140/250.\n",
      "Successfully downloaded 1QB7.pdb to data/raw/1QB7.pdb. 141/250.\n",
      "Successfully downloaded 3OUE.pdb to data/raw/3OUE.pdb. 142/250.\n",
      "Successfully downloaded 2RBK.pdb to data/raw/2RBK.pdb. 143/250.\n",
      "Successfully downloaded 4FD9.pdb to data/raw/4FD9.pdb. 144/250.\n",
      "Successfully downloaded 1BMQ.pdb to data/raw/1BMQ.pdb. 145/250.\n",
      "Successfully downloaded 1DW0.pdb to data/raw/1DW0.pdb. 146/250.\n",
      "Successfully downloaded 1RDZ.pdb to data/raw/1RDZ.pdb. 147/250.\n",
      "Successfully downloaded 2E2O.pdb to data/raw/2E2O.pdb. 148/250.\n",
      "Successfully downloaded 5TAB.pdb to data/raw/5TAB.pdb. 149/250.\n",
      "Successfully downloaded 2H1C.pdb to data/raw/2H1C.pdb. 150/250.\n",
      "Successfully downloaded 1Y7T.pdb to data/raw/1Y7T.pdb. 151/250.\n",
      "Successfully downloaded 4G94.pdb to data/raw/4G94.pdb. 152/250.\n",
      "Successfully downloaded 4P6Q.pdb to data/raw/4P6Q.pdb. 153/250.\n",
      "Successfully downloaded 3G46.pdb to data/raw/3G46.pdb. 154/250.\n",
      "Successfully downloaded 4Y0A.pdb to data/raw/4Y0A.pdb. 155/250.\n",
      "Successfully downloaded 1EBF.pdb to data/raw/1EBF.pdb. 156/250.\n",
      "Successfully downloaded 3DXS.pdb to data/raw/3DXS.pdb. 157/250.\n",
      "Successfully downloaded 5K9A.pdb to data/raw/5K9A.pdb. 158/250.\n",
      "Successfully downloaded 2JL1.pdb to data/raw/2JL1.pdb. 159/250.\n",
      "Successfully downloaded 5MF5.pdb to data/raw/5MF5.pdb. 160/250.\n",
      "Successfully downloaded 4DM1.pdb to data/raw/4DM1.pdb. 161/250.\n",
      "Successfully downloaded 4X3L.pdb to data/raw/4X3L.pdb. 162/250.\n",
      "Successfully downloaded 3CXP.pdb to data/raw/3CXP.pdb. 163/250.\n",
      "Successfully downloaded 1UCD.pdb to data/raw/1UCD.pdb. 164/250.\n",
      "Successfully downloaded 1DLJ.pdb to data/raw/1DLJ.pdb. 165/250.\n",
      "Successfully downloaded 1QXX.pdb to data/raw/1QXX.pdb. 166/250.\n",
      "Successfully downloaded 1L3P.pdb to data/raw/1L3P.pdb. 167/250.\n",
      "Successfully downloaded 3SEB.pdb to data/raw/3SEB.pdb. 168/250.\n",
      "Successfully downloaded 1OLL.pdb to data/raw/1OLL.pdb. 169/250.\n",
      "Successfully downloaded 1GVR.pdb to data/raw/1GVR.pdb. 170/250.\n",
      "^C\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Run shell script that takes a .txt file with PDBIDs as input.\\n!./download_and_process_data.sh pdbids_250.txt\";\n",
       "                var nbb_formatted_code = \"# Run shell script that takes a .txt file with PDBIDs as input.\\n!./download_and_process_data.sh pdbids_250.txt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run shell script that takes a .txt file with PDBIDs as input.\n",
    "!./download_and_process_data.sh pdbids_250.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"DEVICE = \\\"cuda\\\"  # \\\"cpu\\\" or \\\"cuda\\\"\\nBATCH_SIZE = 100\\nLEARNING_RATE = 3e-4\\nEPOCHS = 5\\nTRAIN_VAL_SPLIT = 0.8\";\n",
       "                var nbb_formatted_code = \"DEVICE = \\\"cuda\\\"  # \\\"cpu\\\" or \\\"cuda\\\"\\nBATCH_SIZE = 100\\nLEARNING_RATE = 3e-4\\nEPOCHS = 5\\nTRAIN_VAL_SPLIT = 0.8\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DEVICE = \"cuda\"  # \"cpu\" or \"cuda\"\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 3e-4\n",
    "EPOCHS = 5\n",
    "TRAIN_VAL_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"class ResidueEnvironment:\\n    \\\"\\\"\\\"\\n    Residue environment class used to hold necessarry information about the\\n    atoms of the environment such as atomic coordinates, atom types and the\\n    class of the missing central amino acid.\\n\\n    Parameters\\n    ----------\\n    xyz_coords: np.ndarray\\n        Numpy array with shape (n_atoms, 3) containing the x, y, z coordinates.\\n    atom_types: np.ndarray\\n        1D numpy array containing the atom types. Integer values in range(6).\\n    restypes_onehot: np.ndarray\\n        Numpy array with shape (n_atoms, 21) containing the amino acid\\n        class of the missing amino acid\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        xyz_coords: np.ndarray,\\n        atom_types: np.ndarray,\\n        restypes_onehot: np.ndarray,\\n    ):\\n        self._xyz_coords = xyz_coords\\n        self._atom_types = atom_types\\n        self._restypes_onehot = restypes_onehot\\n\\n    @property\\n    def xyz_coords(self):\\n        return self._xyz_coords\\n\\n    @property\\n    def atom_types(self):\\n        return self._atom_types\\n\\n    @property\\n    def restypes_onehot(self):\\n        return self._restypes_onehot\\n\\n    def __repr__(self):\\n        return (\\n            f\\\"<ResidueEnvironment objects with {self.xyz_coords.shape[0]} \\\"\\n            f\\\"atoms and residue class {np.argmax(self.restypes_onehot)}>\\\"\\n        )\\n\\n\\nclass ResidueEnvironmentsDataset(Dataset):\\n    \\\"\\\"\\\"\\n    Residue environment dataset class\\n\\n    Parameters\\n    ----------\\n    npz_filenames: List[str]\\n        List of parsed pdb filenames in .npz format\\n    transform: Callable\\n        A to-tensor transformer class\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, npz_filenames: List[str], transform: Callable = None):\\n        self._res_env_objects = self._parse_envs(npz_filenames)\\n        self._transform = transform\\n\\n    @property\\n    def res_env_objects(self):\\n        return self._res_env_objects\\n\\n    @property\\n    def transform(self):\\n        return self._transform\\n\\n    def __len__(self):\\n        return len(self.res_env_objects)\\n\\n    def __getitem__(self, idx):\\n        sample = self.res_env_objects[idx]\\n        if self.transform:\\n            sample = self.transform(sample)\\n        return sample\\n\\n    def _parse_envs(self, npz_filenames: List[str]) -> List[ResidueEnvironment]:\\n        res_env_objects = []\\n        for i in range(len(npz_filenames)):\\n            coordinate_features = np.load(npz_filenames[i])\\n            atom_coords_prot_seq = coordinate_features[\\\"positions\\\"]\\n            restypes_onehots_prot_seq = coordinate_features[\\\"aa_onehot\\\"]\\n            selector_prot_seq = coordinate_features[\\\"selector\\\"]\\n            atom_types_flattened = coordinate_features[\\\"atom_types_numeric\\\"]\\n            N_residues = selector_prot_seq.shape[0]\\n            for resi_i in range(N_residues):\\n                selector = selector_prot_seq[resi_i]\\n                selector_masked = selector[selector > -1]  # Remove Filler\\n                coords_mask = (\\n                    atom_coords_prot_seq[resi_i, :, 0] != -99.0\\n                )  # Remove filler\\n                coords = atom_coords_prot_seq[resi_i][coords_mask]\\n                atom_types = atom_types_flattened[selector_masked]\\n                restypes_onehot = restypes_onehots_prot_seq[resi_i]\\n                res_env_objects.append(\\n                    ResidueEnvironment(coords, atom_types, restypes_onehot)\\n                )\\n        return res_env_objects\\n\\n\\nclass ToTensor:\\n    \\\"\\\"\\\" To-tensor transformer class\\\"\\\"\\\"\\n\\n    def __call__(self, sample: ResidueEnvironment):\\n        \\\"\\\"\\\"Converts single ResidueEnvironment object into x_ and y_\\\"\\\"\\\"\\n\\n        sample_env = np.hstack(\\n            [np.reshape(sample.atom_types, [-1, 1]), sample.xyz_coords]\\n        )\\n\\n        return {\\n            \\\"x_\\\": torch.tensor(sample_env, dtype=torch.float32).to(DEVICE),\\n            \\\"y_\\\": torch.tensor(\\n                np.array(sample.restypes_onehot), dtype=torch.float32\\n            ).to(DEVICE),\\n        }\\n\\n    @staticmethod\\n    def collate_cat(batch: List[ResidueEnvironment]):\\n        \\\"\\\"\\\"\\n        Collate method used by the dataloader to collate a\\n        batch of ResidueEnvironment objects.\\n        \\\"\\\"\\\"\\n        target = torch.cat([torch.unsqueeze(b[\\\"y_\\\"], 0) for b in batch], dim=0)\\n\\n        # To collate the input, we need to add a column which\\n        # specifies the environtment each atom belongs to\\n        env_id_batch = []\\n        for i, b in enumerate(batch):\\n            n_atoms = b[\\\"x_\\\"].shape[0]\\n            env_id_arr = torch.zeros(n_atoms, dtype=torch.float32).to(DEVICE) + i\\n            env_id_batch.append(\\n                torch.cat([torch.unsqueeze(env_id_arr, 1), b[\\\"x_\\\"]], dim=1)\\n            )\\n        data = torch.cat(env_id_batch, dim=0)\\n\\n        return data, target\";\n",
       "                var nbb_formatted_code = \"class ResidueEnvironment:\\n    \\\"\\\"\\\"\\n    Residue environment class used to hold necessarry information about the\\n    atoms of the environment such as atomic coordinates, atom types and the\\n    class of the missing central amino acid.\\n\\n    Parameters\\n    ----------\\n    xyz_coords: np.ndarray\\n        Numpy array with shape (n_atoms, 3) containing the x, y, z coordinates.\\n    atom_types: np.ndarray\\n        1D numpy array containing the atom types. Integer values in range(6).\\n    restypes_onehot: np.ndarray\\n        Numpy array with shape (n_atoms, 21) containing the amino acid\\n        class of the missing amino acid\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        xyz_coords: np.ndarray,\\n        atom_types: np.ndarray,\\n        restypes_onehot: np.ndarray,\\n    ):\\n        self._xyz_coords = xyz_coords\\n        self._atom_types = atom_types\\n        self._restypes_onehot = restypes_onehot\\n\\n    @property\\n    def xyz_coords(self):\\n        return self._xyz_coords\\n\\n    @property\\n    def atom_types(self):\\n        return self._atom_types\\n\\n    @property\\n    def restypes_onehot(self):\\n        return self._restypes_onehot\\n\\n    def __repr__(self):\\n        return (\\n            f\\\"<ResidueEnvironment objects with {self.xyz_coords.shape[0]} \\\"\\n            f\\\"atoms and residue class {np.argmax(self.restypes_onehot)}>\\\"\\n        )\\n\\n\\nclass ResidueEnvironmentsDataset(Dataset):\\n    \\\"\\\"\\\"\\n    Residue environment dataset class\\n\\n    Parameters\\n    ----------\\n    npz_filenames: List[str]\\n        List of parsed pdb filenames in .npz format\\n    transform: Callable\\n        A to-tensor transformer class\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, npz_filenames: List[str], transform: Callable = None):\\n        self._res_env_objects = self._parse_envs(npz_filenames)\\n        self._transform = transform\\n\\n    @property\\n    def res_env_objects(self):\\n        return self._res_env_objects\\n\\n    @property\\n    def transform(self):\\n        return self._transform\\n\\n    def __len__(self):\\n        return len(self.res_env_objects)\\n\\n    def __getitem__(self, idx):\\n        sample = self.res_env_objects[idx]\\n        if self.transform:\\n            sample = self.transform(sample)\\n        return sample\\n\\n    def _parse_envs(self, npz_filenames: List[str]) -> List[ResidueEnvironment]:\\n        res_env_objects = []\\n        for i in range(len(npz_filenames)):\\n            coordinate_features = np.load(npz_filenames[i])\\n            atom_coords_prot_seq = coordinate_features[\\\"positions\\\"]\\n            restypes_onehots_prot_seq = coordinate_features[\\\"aa_onehot\\\"]\\n            selector_prot_seq = coordinate_features[\\\"selector\\\"]\\n            atom_types_flattened = coordinate_features[\\\"atom_types_numeric\\\"]\\n            N_residues = selector_prot_seq.shape[0]\\n            for resi_i in range(N_residues):\\n                selector = selector_prot_seq[resi_i]\\n                selector_masked = selector[selector > -1]  # Remove Filler\\n                coords_mask = (\\n                    atom_coords_prot_seq[resi_i, :, 0] != -99.0\\n                )  # Remove filler\\n                coords = atom_coords_prot_seq[resi_i][coords_mask]\\n                atom_types = atom_types_flattened[selector_masked]\\n                restypes_onehot = restypes_onehots_prot_seq[resi_i]\\n                res_env_objects.append(\\n                    ResidueEnvironment(coords, atom_types, restypes_onehot)\\n                )\\n        return res_env_objects\\n\\n\\nclass ToTensor:\\n    \\\"\\\"\\\" To-tensor transformer class\\\"\\\"\\\"\\n\\n    def __call__(self, sample: ResidueEnvironment):\\n        \\\"\\\"\\\"Converts single ResidueEnvironment object into x_ and y_\\\"\\\"\\\"\\n\\n        sample_env = np.hstack(\\n            [np.reshape(sample.atom_types, [-1, 1]), sample.xyz_coords]\\n        )\\n\\n        return {\\n            \\\"x_\\\": torch.tensor(sample_env, dtype=torch.float32).to(DEVICE),\\n            \\\"y_\\\": torch.tensor(\\n                np.array(sample.restypes_onehot), dtype=torch.float32\\n            ).to(DEVICE),\\n        }\\n\\n    @staticmethod\\n    def collate_cat(batch: List[ResidueEnvironment]):\\n        \\\"\\\"\\\"\\n        Collate method used by the dataloader to collate a\\n        batch of ResidueEnvironment objects.\\n        \\\"\\\"\\\"\\n        target = torch.cat([torch.unsqueeze(b[\\\"y_\\\"], 0) for b in batch], dim=0)\\n\\n        # To collate the input, we need to add a column which\\n        # specifies the environtment each atom belongs to\\n        env_id_batch = []\\n        for i, b in enumerate(batch):\\n            n_atoms = b[\\\"x_\\\"].shape[0]\\n            env_id_arr = torch.zeros(n_atoms, dtype=torch.float32).to(DEVICE) + i\\n            env_id_batch.append(\\n                torch.cat([torch.unsqueeze(env_id_arr, 1), b[\\\"x_\\\"]], dim=1)\\n            )\\n        data = torch.cat(env_id_batch, dim=0)\\n\\n        return data, target\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ResidueEnvironment:\n",
    "    \"\"\"\n",
    "    Residue environment class used to hold necessarry information about the\n",
    "    atoms of the environment such as atomic coordinates, atom types and the\n",
    "    class of the missing central amino acid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyz_coords: np.ndarray\n",
    "        Numpy array with shape (n_atoms, 3) containing the x, y, z coordinates.\n",
    "    atom_types: np.ndarray\n",
    "        1D numpy array containing the atom types. Integer values in range(6).\n",
    "    restypes_onehot: np.ndarray\n",
    "        Numpy array with shape (n_atoms, 21) containing the amino acid\n",
    "        class of the missing amino acid\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        xyz_coords: np.ndarray,\n",
    "        atom_types: np.ndarray,\n",
    "        restypes_onehot: np.ndarray,\n",
    "    ):\n",
    "        self._xyz_coords = xyz_coords\n",
    "        self._atom_types = atom_types\n",
    "        self._restypes_onehot = restypes_onehot\n",
    "\n",
    "    @property\n",
    "    def xyz_coords(self):\n",
    "        return self._xyz_coords\n",
    "\n",
    "    @property\n",
    "    def atom_types(self):\n",
    "        return self._atom_types\n",
    "\n",
    "    @property\n",
    "    def restypes_onehot(self):\n",
    "        return self._restypes_onehot\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"<ResidueEnvironment objects with {self.xyz_coords.shape[0]} \"\n",
    "            f\"atoms and residue class {np.argmax(self.restypes_onehot)}>\"\n",
    "        )\n",
    "\n",
    "\n",
    "class ResidueEnvironmentsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Residue environment dataset class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    npz_filenames: List[str]\n",
    "        List of parsed pdb filenames in .npz format\n",
    "    transform: Callable\n",
    "        A to-tensor transformer class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, npz_filenames: List[str], transform: Callable = None):\n",
    "        self._res_env_objects = self._parse_envs(npz_filenames)\n",
    "        self._transform = transform\n",
    "\n",
    "    @property\n",
    "    def res_env_objects(self):\n",
    "        return self._res_env_objects\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return self._transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.res_env_objects)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.res_env_objects[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def _parse_envs(self, npz_filenames: List[str]) -> List[ResidueEnvironment]:\n",
    "        res_env_objects = []\n",
    "        for i in range(len(npz_filenames)):\n",
    "            coordinate_features = np.load(npz_filenames[i])\n",
    "            atom_coords_prot_seq = coordinate_features[\"positions\"]\n",
    "            restypes_onehots_prot_seq = coordinate_features[\"aa_onehot\"]\n",
    "            selector_prot_seq = coordinate_features[\"selector\"]\n",
    "            atom_types_flattened = coordinate_features[\"atom_types_numeric\"]\n",
    "            N_residues = selector_prot_seq.shape[0]\n",
    "            for resi_i in range(N_residues):\n",
    "                selector = selector_prot_seq[resi_i]\n",
    "                selector_masked = selector[selector > -1]  # Remove Filler\n",
    "                coords_mask = (\n",
    "                    atom_coords_prot_seq[resi_i, :, 0] != -99.0\n",
    "                )  # Remove filler\n",
    "                coords = atom_coords_prot_seq[resi_i][coords_mask]\n",
    "                atom_types = atom_types_flattened[selector_masked]\n",
    "                restypes_onehot = restypes_onehots_prot_seq[resi_i]\n",
    "                res_env_objects.append(\n",
    "                    ResidueEnvironment(coords, atom_types, restypes_onehot)\n",
    "                )\n",
    "        return res_env_objects\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\" To-tensor transformer class\"\"\"\n",
    "\n",
    "    def __call__(self, sample: ResidueEnvironment):\n",
    "        \"\"\"Converts single ResidueEnvironment object into x_ and y_\"\"\"\n",
    "\n",
    "        sample_env = np.hstack(\n",
    "            [np.reshape(sample.atom_types, [-1, 1]), sample.xyz_coords]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"x_\": torch.tensor(sample_env, dtype=torch.float32).to(DEVICE),\n",
    "            \"y_\": torch.tensor(\n",
    "                np.array(sample.restypes_onehot), dtype=torch.float32\n",
    "            ).to(DEVICE),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_cat(batch: List[ResidueEnvironment]):\n",
    "        \"\"\"\n",
    "        Collate method used by the dataloader to collate a\n",
    "        batch of ResidueEnvironment objects.\n",
    "        \"\"\"\n",
    "        target = torch.cat([torch.unsqueeze(b[\"y_\"], 0) for b in batch], dim=0)\n",
    "\n",
    "        # To collate the input, we need to add a column which\n",
    "        # specifies the environtment each atom belongs to\n",
    "        env_id_batch = []\n",
    "        for i, b in enumerate(batch):\n",
    "            n_atoms = b[\"x_\"].shape[0]\n",
    "            env_id_arr = torch.zeros(\n",
    "                n_atoms, dtype=torch.float32).to(DEVICE) + i\n",
    "            env_id_batch.append(\n",
    "                torch.cat([torch.unsqueeze(env_id_arr, 1), b[\"x_\"]], dim=1)\n",
    "            )\n",
    "        data = torch.cat(env_id_batch, dim=0)\n",
    "\n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class CavityModel(torch.nn.Module):\\n    \\\"\\\"\\\"\\n    3D convolutional neural network to missing amino acid classification\\n\\n    Parameters\\n    ----------\\n    n_atom_types: int\\n        Number of atom types. (C, H, N, O, S, P)\\n    bins_per_angstrom: float\\n        Number of grid points per Anstrom.\\n    grid_dim: int\\n        Grid dimension\\n    sigma: float\\n        Standard deviation used for gaussian blurring\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        n_atom_types: int = 6,\\n        bins_per_angstrom: float = 1.0,\\n        grid_dim: int = 18,\\n        sigma: float = 0.6,\\n    ):\\n        super().__init__()\\n\\n        self._n_atom_types = n_atom_types\\n        self._bins_per_angstrom = bins_per_angstrom\\n        self._grid_dim = grid_dim\\n        self._sigma = sigma\\n\\n        self._model()\\n\\n    @property\\n    def n_atom_types(self):\\n        return self._n_atom_types\\n\\n    @property\\n    def bins_per_angstrom(self):\\n        return self._bins_per_angstrom\\n\\n    @property\\n    def grid_dim(self):\\n        return self._grid_dim\\n\\n    @property\\n    def sigma(self):\\n        return self._sigma\\n\\n    @property\\n    def sigma_p(self):\\n        return self.sigma * self.bins_per_angstrom\\n\\n    @property\\n    def lin_spacing(self):\\n        lin_spacing = np.linspace(\\n            start=-self.grid_dim / 2 * self.bins_per_angstrom\\n            + self.bins_per_angstrom / 2,\\n            stop=self.grid_dim / 2 * self.bins_per_angstrom\\n            - self.bins_per_angstrom / 2,\\n            num=self.grid_dim,\\n        )\\n        return lin_spacing\\n\\n    def _model(self):\\n        self.xx, self.yy, self.zz = torch.tensor(\\n            np.meshgrid(\\n                self.lin_spacing, self.lin_spacing, self.lin_spacing, indexing=\\\"ij\\\"\\n            ),\\n            dtype=torch.float32,\\n        ).to(DEVICE)\\n\\n        self.conv1 = torch.nn.Sequential(\\n            torch.nn.Conv3d(6, 16, kernel_size=(3, 3, 3), stride=2, padding=1),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm3d(16),\\n        )\\n        self.conv2 = torch.nn.Sequential(\\n            torch.nn.Conv3d(16, 32, kernel_size=(3, 3, 3), stride=2, padding=0),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm3d(32),\\n        )\\n        self.conv3 = torch.nn.Sequential(\\n            torch.nn.Conv3d(32, 64, kernel_size=(3, 3, 3), stride=1, padding=1),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm3d(64),\\n            torch.nn.Flatten(),\\n        )\\n        self.dense1 = torch.nn.Sequential(\\n            torch.nn.Linear(in_features=4096, out_features=128),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm1d(128),\\n        )\\n        self.dense2 = torch.nn.Linear(in_features=128, out_features=21)\\n\\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\\n        x = self._gaussian_blurring(x)\\n        x = self.conv1(x)\\n        x = self.conv2(x)\\n        x = self.conv3(x)\\n        x = self.dense1(x)\\n        x = self.dense2(x)\\n        return x\\n\\n    def _gaussian_blurring(self, x: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Method that takes 2d torch.Tensor describing the atoms of the batch.\\n\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n            Tensor for shape (n_atoms, 5). Each row represents an atom, where:\\n                column 0 describes the environment of the batch the\\n                atom belongs to\\n                column 1 describes the atom type\\n                column 2,3,4 are the x, y, z coordinates, respectively\\n\\n        Returns\\n        -------\\n        fields_torch: torch.Tensor\\n            Represents the structural environment with gaussian blurring\\n            and has shape (-1, self.grid_dim, self.grid_dim, self.grid_dim).\\n        \\\"\\\"\\\"\\n        current_batch_size = torch.unique(x[:, 0]).shape[0]\\n        fields_torch = torch.zeros(\\n            (\\n                current_batch_size,\\n                self.n_atom_types,\\n                self.grid_dim,\\n                self.grid_dim,\\n                self.grid_dim,\\n            )\\n        ).to(DEVICE)\\n        for j in range(self.n_atom_types):\\n            mask_j = x[:, 1] == j\\n            atom_type_j_data = x[mask_j]\\n            if atom_type_j_data.shape[0] > 0:\\n                pos = atom_type_j_data[:, 2:]\\n                density = torch.exp(\\n                    -(\\n                        (torch.reshape(self.xx, [-1, 1]) - pos[:, 0]) ** 2\\n                        + (torch.reshape(self.yy, [-1, 1]) - pos[:, 1]) ** 2\\n                        + (torch.reshape(self.zz, [-1, 1]) - pos[:, 2]) ** 2\\n                    )\\n                    / (2 * self.sigma_p ** 2)\\n                )\\n\\n                # Normalize each atom to 1\\n                density /= torch.sum(density, dim=0)\\n\\n                # Since column 0 of atom_type_j_data is sorted\\n                # I can use a trick to detect the boundaries based\\n                # on the change from one value to another.\\n                change_mask_j = (\\n                    atom_type_j_data[:, 0][:-1] != atom_type_j_data[:, 0][1:]\\n                )\\n\\n                # Add begin and end indices\\n                ranges_i = torch.cat(\\n                    [\\n                        torch.tensor([0]),\\n                        torch.arange(atom_type_j_data.shape[0] - 1)[change_mask_j] + 1,\\n                        torch.tensor([atom_type_j_data.shape[0]]),\\n                    ]\\n                )\\n\\n                # Fill tensor\\n                for i in range(ranges_i.shape[0]):\\n                    if i < ranges_i.shape[0] - 1:\\n                        index_0, index_1 = ranges_i[i], ranges_i[i + 1]\\n                        fields = torch.reshape(\\n                            torch.sum(density[:, index_0:index_1], dim=1),\\n                            [self.grid_dim, self.grid_dim, self.grid_dim],\\n                        )\\n                        fields_torch[i, j, :, :, :] = fields\\n        return fields_torch\";\n",
       "                var nbb_formatted_code = \"class CavityModel(torch.nn.Module):\\n    \\\"\\\"\\\"\\n    3D convolutional neural network to missing amino acid classification\\n\\n    Parameters\\n    ----------\\n    n_atom_types: int\\n        Number of atom types. (C, H, N, O, S, P)\\n    bins_per_angstrom: float\\n        Number of grid points per Anstrom.\\n    grid_dim: int\\n        Grid dimension\\n    sigma: float\\n        Standard deviation used for gaussian blurring\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        n_atom_types: int = 6,\\n        bins_per_angstrom: float = 1.0,\\n        grid_dim: int = 18,\\n        sigma: float = 0.6,\\n    ):\\n        super().__init__()\\n\\n        self._n_atom_types = n_atom_types\\n        self._bins_per_angstrom = bins_per_angstrom\\n        self._grid_dim = grid_dim\\n        self._sigma = sigma\\n\\n        self._model()\\n\\n    @property\\n    def n_atom_types(self):\\n        return self._n_atom_types\\n\\n    @property\\n    def bins_per_angstrom(self):\\n        return self._bins_per_angstrom\\n\\n    @property\\n    def grid_dim(self):\\n        return self._grid_dim\\n\\n    @property\\n    def sigma(self):\\n        return self._sigma\\n\\n    @property\\n    def sigma_p(self):\\n        return self.sigma * self.bins_per_angstrom\\n\\n    @property\\n    def lin_spacing(self):\\n        lin_spacing = np.linspace(\\n            start=-self.grid_dim / 2 * self.bins_per_angstrom\\n            + self.bins_per_angstrom / 2,\\n            stop=self.grid_dim / 2 * self.bins_per_angstrom\\n            - self.bins_per_angstrom / 2,\\n            num=self.grid_dim,\\n        )\\n        return lin_spacing\\n\\n    def _model(self):\\n        self.xx, self.yy, self.zz = torch.tensor(\\n            np.meshgrid(\\n                self.lin_spacing, self.lin_spacing, self.lin_spacing, indexing=\\\"ij\\\"\\n            ),\\n            dtype=torch.float32,\\n        ).to(DEVICE)\\n\\n        self.conv1 = torch.nn.Sequential(\\n            torch.nn.Conv3d(6, 16, kernel_size=(3, 3, 3), stride=2, padding=1),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm3d(16),\\n        )\\n        self.conv2 = torch.nn.Sequential(\\n            torch.nn.Conv3d(16, 32, kernel_size=(3, 3, 3), stride=2, padding=0),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm3d(32),\\n        )\\n        self.conv3 = torch.nn.Sequential(\\n            torch.nn.Conv3d(32, 64, kernel_size=(3, 3, 3), stride=1, padding=1),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm3d(64),\\n            torch.nn.Flatten(),\\n        )\\n        self.dense1 = torch.nn.Sequential(\\n            torch.nn.Linear(in_features=4096, out_features=128),\\n            torch.nn.ReLU(),\\n            torch.nn.BatchNorm1d(128),\\n        )\\n        self.dense2 = torch.nn.Linear(in_features=128, out_features=21)\\n\\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\\n        x = self._gaussian_blurring(x)\\n        x = self.conv1(x)\\n        x = self.conv2(x)\\n        x = self.conv3(x)\\n        x = self.dense1(x)\\n        x = self.dense2(x)\\n        return x\\n\\n    def _gaussian_blurring(self, x: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Method that takes 2d torch.Tensor describing the atoms of the batch.\\n\\n        Parameters\\n        ----------\\n        x: torch.Tensor\\n            Tensor for shape (n_atoms, 5). Each row represents an atom, where:\\n                column 0 describes the environment of the batch the\\n                atom belongs to\\n                column 1 describes the atom type\\n                column 2,3,4 are the x, y, z coordinates, respectively\\n\\n        Returns\\n        -------\\n        fields_torch: torch.Tensor\\n            Represents the structural environment with gaussian blurring\\n            and has shape (-1, self.grid_dim, self.grid_dim, self.grid_dim).\\n        \\\"\\\"\\\"\\n        current_batch_size = torch.unique(x[:, 0]).shape[0]\\n        fields_torch = torch.zeros(\\n            (\\n                current_batch_size,\\n                self.n_atom_types,\\n                self.grid_dim,\\n                self.grid_dim,\\n                self.grid_dim,\\n            )\\n        ).to(DEVICE)\\n        for j in range(self.n_atom_types):\\n            mask_j = x[:, 1] == j\\n            atom_type_j_data = x[mask_j]\\n            if atom_type_j_data.shape[0] > 0:\\n                pos = atom_type_j_data[:, 2:]\\n                density = torch.exp(\\n                    -(\\n                        (torch.reshape(self.xx, [-1, 1]) - pos[:, 0]) ** 2\\n                        + (torch.reshape(self.yy, [-1, 1]) - pos[:, 1]) ** 2\\n                        + (torch.reshape(self.zz, [-1, 1]) - pos[:, 2]) ** 2\\n                    )\\n                    / (2 * self.sigma_p ** 2)\\n                )\\n\\n                # Normalize each atom to 1\\n                density /= torch.sum(density, dim=0)\\n\\n                # Since column 0 of atom_type_j_data is sorted\\n                # I can use a trick to detect the boundaries based\\n                # on the change from one value to another.\\n                change_mask_j = (\\n                    atom_type_j_data[:, 0][:-1] != atom_type_j_data[:, 0][1:]\\n                )\\n\\n                # Add begin and end indices\\n                ranges_i = torch.cat(\\n                    [\\n                        torch.tensor([0]),\\n                        torch.arange(atom_type_j_data.shape[0] - 1)[change_mask_j] + 1,\\n                        torch.tensor([atom_type_j_data.shape[0]]),\\n                    ]\\n                )\\n\\n                # Fill tensor\\n                for i in range(ranges_i.shape[0]):\\n                    if i < ranges_i.shape[0] - 1:\\n                        index_0, index_1 = ranges_i[i], ranges_i[i + 1]\\n                        fields = torch.reshape(\\n                            torch.sum(density[:, index_0:index_1], dim=1),\\n                            [self.grid_dim, self.grid_dim, self.grid_dim],\\n                        )\\n                        fields_torch[i, j, :, :, :] = fields\\n        return fields_torch\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CavityModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    3D convolutional neural network to missing amino acid classification\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_atom_types: int\n",
    "        Number of atom types. (C, H, N, O, S, P)\n",
    "    bins_per_angstrom: float\n",
    "        Number of grid points per Anstrom.\n",
    "    grid_dim: int\n",
    "        Grid dimension\n",
    "    sigma: float\n",
    "        Standard deviation used for gaussian blurring\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_atom_types: int = 6,\n",
    "        bins_per_angstrom: float = 1.0,\n",
    "        grid_dim: int = 18,\n",
    "        sigma: float = 0.6,):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self._n_atom_types = n_atom_types\n",
    "        self._bins_per_angstrom = bins_per_angstrom\n",
    "        self._grid_dim = grid_dim\n",
    "        self._sigma = sigma\n",
    "\n",
    "        self._model()\n",
    "\n",
    "    @property\n",
    "    def n_atom_types(self):\n",
    "        return self._n_atom_types\n",
    "\n",
    "    @property\n",
    "    def bins_per_angstrom(self):\n",
    "        return self._bins_per_angstrom\n",
    "\n",
    "    @property\n",
    "    def grid_dim(self):\n",
    "        return self._grid_dim\n",
    "\n",
    "    @property\n",
    "    def sigma(self):\n",
    "        return self._sigma\n",
    "\n",
    "    @property\n",
    "    def sigma_p(self):\n",
    "        return self.sigma * self.bins_per_angstrom\n",
    "\n",
    "    @property\n",
    "    def lin_spacing(self):\n",
    "        lin_spacing = np.linspace(\n",
    "            start=-self.grid_dim / 2 * self.bins_per_angstrom\n",
    "            + self.bins_per_angstrom / 2,\n",
    "            stop=self.grid_dim / 2 * self.bins_per_angstrom\n",
    "            - self.bins_per_angstrom / 2,\n",
    "            num=self.grid_dim,\n",
    "        )\n",
    "        return lin_spacing\n",
    "\n",
    "    def _model(self):\n",
    "        self.xx, self.yy, self.zz = torch.tensor(\n",
    "            np.meshgrid(\n",
    "                self.lin_spacing, self.lin_spacing, \n",
    "                self.lin_spacing, indexing=\"ij\"\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(6, 16, kernel_size=(3, 3, 3), \n",
    "                            stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm3d(16),\n",
    "        )\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(16, 32, kernel_size=(3, 3, 3), \n",
    "                            stride=2, padding=0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm3d(32),\n",
    "        )\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(32, 64, kernel_size=(3, 3, 3), \n",
    "                            stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm3d(64),\n",
    "            torch.nn.Flatten(),\n",
    "        )\n",
    "        self.dense1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=4096, out_features=128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "        )\n",
    "        self.dense2 = torch.nn.Linear(in_features=128, out_features=21)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._gaussian_blurring(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "    def _gaussian_blurring(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Method that takes 2d torch.Tensor describing the atoms of the batch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Tensor for shape (n_atoms, 5). Each row represents an atom, where:\n",
    "                column 0 describes the environment of the batch the\n",
    "                atom belongs to\n",
    "                column 1 describes the atom type\n",
    "                column 2,3,4 are the x, y, z coordinates, respectively\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fields_torch: torch.Tensor\n",
    "            Represents the structural environment with gaussian blurring\n",
    "            and has shape (-1, self.grid_dim, self.grid_dim, self.grid_dim).\n",
    "        \"\"\"\n",
    "        current_batch_size = torch.unique(x[:, 0]).shape[0]\n",
    "        fields_torch = torch.zeros(\n",
    "            (\n",
    "                current_batch_size,\n",
    "                self.n_atom_types,\n",
    "                self.grid_dim,\n",
    "                self.grid_dim,\n",
    "                self.grid_dim,\n",
    "            )\n",
    "        ).to(DEVICE)\n",
    "        for j in range(self.n_atom_types):\n",
    "            mask_j = x[:, 1] == j\n",
    "            atom_type_j_data = x[mask_j]\n",
    "            if atom_type_j_data.shape[0] > 0:\n",
    "                pos = atom_type_j_data[:, 2:]\n",
    "                density = torch.exp(\n",
    "                    -(\n",
    "                        (torch.reshape(self.xx, [-1, 1]) - pos[:, 0]) ** 2\n",
    "                        + (torch.reshape(self.yy, [-1, 1]) - pos[:, 1]) ** 2\n",
    "                        + (torch.reshape(self.zz, [-1, 1]) - pos[:, 2]) ** 2\n",
    "                    )\n",
    "                    / (2 * self.sigma_p ** 2)\n",
    "                )\n",
    "\n",
    "                # Normalize each atom to 1\n",
    "                density /= torch.sum(density, dim=0)\n",
    "\n",
    "                # Since column 0 of atom_type_j_data is sorted\n",
    "                # I can use a trick to detect the boundaries based\n",
    "                # on the change from one value to another.\n",
    "                change_mask_j = (\n",
    "                    atom_type_j_data[:, 0][:-1] != atom_type_j_data[:, 0][1:]\n",
    "                )\n",
    "\n",
    "                # Add begin and end indices\n",
    "                ranges_i = torch.cat(\n",
    "                    [\n",
    "                        torch.tensor([0]),\n",
    "                        torch.arange(\n",
    "                            atom_type_j_data.shape[0] - 1)[change_mask_j] + 1,\n",
    "                        torch.tensor([atom_type_j_data.shape[0]]),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # Fill tensor\n",
    "                for i in range(ranges_i.shape[0]):\n",
    "                    if i < ranges_i.shape[0] - 1:\n",
    "                        index_0, index_1 = ranges_i[i], ranges_i[i + 1]\n",
    "                        fields = torch.reshape(\n",
    "                            torch.sum(density[:, index_0:index_1], dim=1),\n",
    "                            [self.grid_dim, self.grid_dim, self.grid_dim],\n",
    "                        )\n",
    "                        fields_torch[i, j, :, :, :] = fields\n",
    "        return fields_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set includes 40 pdbs with 18185 environments.\n",
      "Validation data setincludes 10 pdbs with 3189 environments.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"parsed_pdb_filenames = sorted(glob.glob(\\\"data/parsed/*coord*\\\"))\\nrandom.shuffle(parsed_pdb_filenames)\\n\\nn_train_pdbs = int(len(parsed_pdb_filenames) * TRAIN_VAL_SPLIT)\\nfilenames_train = parsed_pdb_filenames[:n_train_pdbs]\\nfilenames_val = parsed_pdb_filenames[n_train_pdbs:]\\n\\ndataset_train = ResidueEnvironmentsDataset(filenames_train, transform=ToTensor())\\ndataset_val = ResidueEnvironmentsDataset(filenames_val, transform=ToTensor())\\n\\ndataloader_train = DataLoader(\\n    dataset_train,\\n    batch_size=BATCH_SIZE,\\n    shuffle=True,\\n    collate_fn=ToTensor.collate_cat,\\n    drop_last=True,\\n)\\ndataloader_val = DataLoader(\\n    dataset_val,\\n    batch_size=BATCH_SIZE,\\n    shuffle=True,\\n    collate_fn=ToTensor.collate_cat,\\n    drop_last=True,\\n)\\n\\nprint(\\n    f\\\"Training data set includes {len(filenames_train)} pdbs with \\\"\\n    f\\\"{len(dataset_train)} environments.\\\"\\n)\\nprint(\\n    f\\\"Validation data setincludes {len(filenames_val)} pdbs with \\\"\\n    f\\\"{len(dataset_val)} environments.\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"parsed_pdb_filenames = sorted(glob.glob(\\\"data/parsed/*coord*\\\"))\\nrandom.shuffle(parsed_pdb_filenames)\\n\\nn_train_pdbs = int(len(parsed_pdb_filenames) * TRAIN_VAL_SPLIT)\\nfilenames_train = parsed_pdb_filenames[:n_train_pdbs]\\nfilenames_val = parsed_pdb_filenames[n_train_pdbs:]\\n\\ndataset_train = ResidueEnvironmentsDataset(filenames_train, transform=ToTensor())\\ndataset_val = ResidueEnvironmentsDataset(filenames_val, transform=ToTensor())\\n\\ndataloader_train = DataLoader(\\n    dataset_train,\\n    batch_size=BATCH_SIZE,\\n    shuffle=True,\\n    collate_fn=ToTensor.collate_cat,\\n    drop_last=True,\\n)\\ndataloader_val = DataLoader(\\n    dataset_val,\\n    batch_size=BATCH_SIZE,\\n    shuffle=True,\\n    collate_fn=ToTensor.collate_cat,\\n    drop_last=True,\\n)\\n\\nprint(\\n    f\\\"Training data set includes {len(filenames_train)} pdbs with \\\"\\n    f\\\"{len(dataset_train)} environments.\\\"\\n)\\nprint(\\n    f\\\"Validation data setincludes {len(filenames_val)} pdbs with \\\"\\n    f\\\"{len(dataset_val)} environments.\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsed_pdb_filenames = sorted(glob.glob(\"data/parsed/*coord*\"))\n",
    "random.shuffle(parsed_pdb_filenames)\n",
    "\n",
    "n_train_pdbs = int(len(parsed_pdb_filenames) * TRAIN_VAL_SPLIT)\n",
    "filenames_train = parsed_pdb_filenames[:n_train_pdbs]\n",
    "filenames_val = parsed_pdb_filenames[n_train_pdbs:]\n",
    "\n",
    "dataset_train = ResidueEnvironmentsDataset(filenames_train, \n",
    "                                           transform=ToTensor())\n",
    "dataset_val = ResidueEnvironmentsDataset(filenames_val, transform=ToTensor())\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=ToTensor.collate_cat,\n",
    "    drop_last=True,\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=ToTensor.collate_cat,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Training data set includes {len(filenames_train)} pdbs with \"\n",
    "    f\"{len(dataset_train)} environments.\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation data setincludes {len(filenames_val)} pdbs with \"\n",
    "    f\"{len(dataset_val)} environments.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_step(\n",
    "    cavity_model: CavityModel,\n",
    "    optimizer: torch.optim.Adam,\n",
    "    loss_function: torch.nn.CrossEntropyLoss,\n",
    ") -> (torch.Tensor, float):\n",
    "    cavity_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    batch_y_pred = cavity_model(batch_x)\n",
    "    loss_batch = loss_function(batch_y_pred, torch.argmax(batch_y, dim=-1))\n",
    "    loss_batch.backward()\n",
    "    optimizer.step()\n",
    "    return (batch_y_pred, loss_batch.detach().cpu().item())\n",
    "\n",
    "\n",
    "# Define model\n",
    "cavity_model = CavityModel().to(DEVICE)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cavity_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_running_mean = 0.0\n",
    "    labels_true = []\n",
    "    labels_pred = []\n",
    "    for batch_x, batch_y in dataloader_train:\n",
    "        # Take train step\n",
    "        batch_y_pred, loss_batch = _train_step(cavity_model, optimizer, \n",
    "                                               loss_function)\n",
    "\n",
    "        # Exponential running mean for the loss\n",
    "        loss_running_mean = loss_running_mean * 0.9 + loss_batch * 0.1\n",
    "\n",
    "        labels_true.append(\n",
    "            torch.argmax(batch_y, dim=-1).detach().cpu().numpy()\n",
    "        )\n",
    "        labels_pred.append(\n",
    "            torch.argmax(batch_y_pred, dim=-1).detach().cpu().numpy()\n",
    "        )\n",
    "    acc_train = np.mean(\n",
    "        (np.reshape(labels_true, -1) == np.reshape(labels_pred, -1))\n",
    "    )\n",
    "\n",
    "    # Eval loop. Due to memory, we don't pass the whole data set to the model\n",
    "    labels_true_val = []\n",
    "    labels_pred_val = []\n",
    "    for batch_x_val, batch_y_val in dataloader_val:\n",
    "        cavity_model.eval()\n",
    "        batch_y_pred_val = cavity_model(batch_x_val)\n",
    "        labels_true_val.append(\n",
    "            torch.argmax(batch_y_val, dim=-1).detach().cpu().numpy()\n",
    "        )\n",
    "        labels_pred_val.append(\n",
    "            torch.argmax(batch_y_pred_val, dim=-1).detach().cpu().numpy()\n",
    "        )\n",
    "    acc_val = np.mean(\n",
    "        (np.reshape(labels_true_val, -1) == np.reshape(labels_pred_val, -1))\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:2d}. Train loss: {loss_running_mean:5.3f}. \"\n",
    "        f\"Train Acc: {acc_train:4.2f}. Val Acc: {acc_val:4.2f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
