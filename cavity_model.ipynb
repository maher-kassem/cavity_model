{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Callable\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 4X2U.pdb to data/raw/4X2U.pdb. 1/10.\n",
      "Successfully downloaded 2X96.pdb to data/raw/2X96.pdb. 2/10.\n",
      "Successfully downloaded 4MXD.pdb to data/raw/4MXD.pdb. 3/10.\n",
      "Successfully downloaded 3E9L.pdb to data/raw/3E9L.pdb. 4/10.\n",
      "Successfully downloaded 1UWC.pdb to data/raw/1UWC.pdb. 5/10.\n",
      "Successfully downloaded 4BGU.pdb to data/raw/4BGU.pdb. 6/10.\n",
      "Successfully downloaded 2YSW.pdb to data/raw/2YSW.pdb. 7/10.\n",
      "Successfully downloaded 4OW4.pdb to data/raw/4OW4.pdb. 8/10.\n",
      "Successfully downloaded 2V5E.pdb to data/raw/2V5E.pdb. 9/10.\n",
      "Successfully downloaded 1IXH.pdb to data/raw/1IXH.pdb. 10/10.\n",
      "Successfully cleaned data/raw/1IXH.pdb and added it to data/cleaned/. 1/10.\n",
      "Successfully cleaned data/raw/1UWC.pdb and added it to data/cleaned/. 2/10.\n",
      "Successfully cleaned data/raw/2V5E.pdb and added it to data/cleaned/. 3/10.\n",
      "Successfully cleaned data/raw/2X96.pdb and added it to data/cleaned/. 4/10.\n",
      "Successfully cleaned data/raw/2YSW.pdb and added it to data/cleaned/. 5/10.\n",
      "Successfully cleaned data/raw/3E9L.pdb and added it to data/cleaned/. 6/10.\n",
      "Successfully cleaned data/raw/4BGU.pdb and added it to data/cleaned/. 7/10.\n",
      "Successfully cleaned data/raw/4MXD.pdb and added it to data/cleaned/. 8/10.\n",
      "Successfully cleaned data/raw/4OW4.pdb and added it to data/cleaned/. 9/10.\n",
      "Successfully cleaned data/raw/4X2U.pdb and added it to data/cleaned/. 10/10.\n",
      "Successfully parsed 1IXH_clean.pdb and moved parsed file to data/parsed. Finished 1/10.\n",
      "Successfully parsed 1UWC_clean.pdb and moved parsed file to data/parsed. Finished 2/10.\n",
      "Successfully parsed 2V5E_clean.pdb and moved parsed file to data/parsed. Finished 3/10.\n",
      "Successfully parsed 2X96_clean.pdb and moved parsed file to data/parsed. Finished 4/10.\n",
      "Successfully parsed 2YSW_clean.pdb and moved parsed file to data/parsed. Finished 5/10.\n",
      "Successfully parsed 3E9L_clean.pdb and moved parsed file to data/parsed. Finished 6/10.\n",
      "Successfully parsed 4BGU_clean.pdb and moved parsed file to data/parsed. Finished 7/10.\n",
      "Successfully parsed 4MXD_clean.pdb and moved parsed file to data/parsed. Finished 8/10.\n",
      "Successfully parsed 4OW4_clean.pdb and moved parsed file to data/parsed. Finished 9/10.\n",
      "Successfully parsed 4X2U_clean.pdb and moved parsed file to data/parsed. Finished 10/10.\n"
     ]
    }
   ],
   "source": [
    "# Run shell script that takes a .txt file with PDBIDs as input.\n",
    "!./download_and_process_data.sh pdbids_010.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"  # \"cpu\" or \"cuda\"\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 3e-4\n",
    "EPOCHS = 10\n",
    "TRAIN_VAL_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidueEnvironment:\n",
    "    \"\"\"\n",
    "    Residue environment class used to hold necessarry information about the \n",
    "    atoms of the environment such as atomic coordinates, atom types and the \n",
    "    class of the missing central amino acid.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coords_2d_arr: np.ndarray \n",
    "        Numpy array with shape (n_atoms, 3) containing the x, y, z coordinates.\n",
    "    atom_types: np.ndarray\n",
    "        1D numpy array containing the atom types. Values range from 0 to 5.\n",
    "    aa_onehot: np.ndarray\n",
    "        Numpy array with shape (n_atoms, 21) containing the amino acid \n",
    "        class of the missing amino acid\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, coords_2d_arr: np.ndarray, \n",
    "                 atom_types: np.ndarray, \n",
    "                 aa_onehot: np.ndarray):\n",
    "        self._coords_2d_arr = coords_2d_arr\n",
    "        self._atom_types = atom_types\n",
    "        self._aa_onehot = aa_onehot\n",
    "        \n",
    "    @property\n",
    "    def coords_2d_arr(self):\n",
    "        return self._coords_2d_arr\n",
    "    \n",
    "    @property\n",
    "    def atom_types(self):\n",
    "        return self._atom_types\n",
    "    \n",
    "    @property\n",
    "    def aa_onehot(self):\n",
    "        return self._aa_onehot\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return (f\"<ResidueEnvironment objects with {self.coords_2d_arr.shape[0]} \"\n",
    "                f\"atoms and residue class {np.argmax(self.aa_onehot)}>\")\n",
    "\n",
    "        \n",
    "class ResidueEnvironmentsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Residue environment dataset class\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    npz_filenames: List[str]\n",
    "        List of parsed pdb files in .npz format\n",
    "    transform: Callable\n",
    "        A to-tensor transformer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, npz_filenames: List[str], transform: Callable = None):\n",
    "        self._res_env_objects = self._parse_envs(npz_filenames)\n",
    "        self._transform = transform\n",
    "        \n",
    "    @property\n",
    "    def res_env_objects(self):\n",
    "        return self._res_env_objects\n",
    "    \n",
    "    @property\n",
    "    def transform(self):\n",
    "        return self._transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.res_env_objects)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.res_env_objects[idx]        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def _parse_envs(self, npz_filenames):\n",
    "        res_env_objects = []\n",
    "        for i in range(len(npz_filenames)):\n",
    "            coordinate_features = np.load(npz_filenames[i])\n",
    "            atom_coords_prot_seq = coordinate_features[\"positions\"]\n",
    "            restype_onehots_prot_seq = coordinate_features[\"aa_onehot\"]\n",
    "            selector_prot_seq = coordinate_features[\"selector\"]\n",
    "            atom_types_flattened = coordinate_features[\"atom_types_numeric\"]\n",
    "            N_residues = selector_prot_seq.shape[0]\n",
    "            for resi_i in range(N_residues):\n",
    "                selector = selector_prot_seq[resi_i]\n",
    "                selector_masked = selector[selector > -1]  # Remove Filler\n",
    "                coords_mask = atom_coords_prot_seq[resi_i, :, 0] != -99.0  # Remove filler\n",
    "                coords = atom_coords_prot_seq[resi_i][coords_mask]            \n",
    "                atom_types = atom_types_flattened[selector_masked]\n",
    "                restype_onehot = restype_onehots_prot_seq[resi_i]\n",
    "                res_env_objects.append(ResidueEnvironment(coords, atom_types, restype_onehot))\n",
    "        return res_env_objects\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):        \n",
    "        sample_env = np.hstack([np.reshape(sample.atom_types, [-1, 1]),\n",
    "                               sample.coords_2d_arr])\n",
    "        \n",
    "        return {\"x_\": torch.tensor(sample_env, dtype=torch.float32).to(DEVICE), \n",
    "                \"y_\": torch.tensor(np.array(sample.aa_onehot), dtype=torch.float32).to(DEVICE)}\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_cat(batch):\n",
    "        \"\"\"\n",
    "        Collate method used by the dataloader to collate a batch.\n",
    "        \"\"\"\n",
    "        target = torch.cat([torch.unsqueeze(b['y_'], 0) for b in batch], dim=0)\n",
    "            \n",
    "        # To collate the input, we need to add a column which \n",
    "        # specifies the environtment each atom belongs to\n",
    "        env_id_batch = []\n",
    "        for i, b in enumerate(batch):\n",
    "            n_atoms = b['x_'].shape[0]\n",
    "            env_id_arr = torch.zeros(n_atoms, dtype=torch.float32).to(DEVICE) + i\n",
    "            env_id_batch.append(torch.cat([torch.unsqueeze(env_id_arr, 1), b['x_']], dim=1))            \n",
    "        data = torch.cat(env_id_batch, dim=0)\n",
    "            \n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CavityModel(torch.nn.Module):\n",
    "    def __init__(self, device: str, sigma: float = 0.6):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.n_atom_types = 6\n",
    "        self.p = 1.0  # Bins per Angstrom\n",
    "        self.n = 18  # Grid size (n, n, n)\n",
    "        self.sigma = sigma  # Width of gaussians used for gaussian blurring\n",
    "        self.sigma_p = self.sigma*self.p\n",
    "        self.a = np.linspace(start=-self.n/2*self.p + self.p/2, \n",
    "                             stop=self.n/2*self.p - self.p/2, \n",
    "                             num=self.n) \n",
    "        self.xx, self.yy, self.zz = torch.tensor(\n",
    "            np.meshgrid(self.a, self.a, self.a, indexing=\"ij\"),\n",
    "            dtype = torch.float32).to(self.device)\n",
    "\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(6, 16, kernel_size=(3,3,3), stride=2, padding=1),\n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.BatchNorm3d(16))\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(16, 32, kernel_size=(3,3,3), stride=2, padding=0),\n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.BatchNorm3d(32))\n",
    "        self.conv3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(32, 64, kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.BatchNorm3d(64),\n",
    "            torch.nn.Flatten())\n",
    "        self.dense1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=4096, out_features=128),\n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.BatchNorm1d(128))\n",
    "        self.dense2 = torch.nn.Linear(in_features=128, out_features=21)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._gaussian_blurring(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x \n",
    "\n",
    "    def _gaussian_blurring(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Method that takes 2d torch.Tensor describing the atoms of the batch.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            Tensor for shape (n_atoms, 5). Each row represents an atom, where:\n",
    "                column 0 describes the environment of the batch the atom belongs to\n",
    "                column 1 describes the atom type\n",
    "                column 2,3,4 are the x, y, z coordinates, respectively\n",
    "        \n",
    "        \"\"\"\n",
    "        current_batch_size = torch.unique(x[:, 0]).shape[0]\n",
    "        fields_torch = torch.zeros((current_batch_size, \n",
    "                                    self.n_atom_types, \n",
    "                                    self.n, self.n, self.n)).to(DEVICE)\n",
    "        for j in range(self.n_atom_types):\n",
    "            mask_j = x[:,1]==j\n",
    "            atom_type_j_data = x[mask_j]\n",
    "            if atom_type_j_data.shape[0] > 0:\n",
    "                pos = atom_type_j_data[:, 2:]\n",
    "                density = torch.exp(\n",
    "                    -(\n",
    "                        (torch.reshape(self.xx, [-1, 1]) - pos[:, 0])**2\n",
    "                      + (torch.reshape(self.yy, [-1, 1]) - pos[:, 1])**2\n",
    "                      + (torch.reshape(self.zz, [-1, 1]) - pos[:, 2])**2\n",
    "                     ) / (2 * self.sigma_p**2))\n",
    "                \n",
    "                # Normalize each atom to 1\n",
    "                density /= torch.sum(density, dim=0)\n",
    "                \n",
    "                # Since column 0 of atom_type_j_data is sorted\n",
    "                # I can use a trick to detect the boundaries based\n",
    "                # on the change from one value to another.\n",
    "                change_mask_j = (atom_type_j_data[:,0][:-1] \n",
    "                                 != atom_type_j_data[:,0][1:])  # detect change in column 0\n",
    "                \n",
    "                # Add begin and end indices\n",
    "                ranges_i = torch.cat(\n",
    "                    [\n",
    "                        torch.tensor([0]),\n",
    "                        torch.arange(atom_type_j_data.shape[0]-1)[change_mask_j]+1, \n",
    "                        torch.tensor([atom_type_j_data.shape[0]])\n",
    "                    ])\n",
    "                \n",
    "                # Fill tensor\n",
    "                for i in range(ranges_i.shape[0]):\n",
    "                    if i < ranges_i.shape[0] - 1:\n",
    "                        index_0, index_1 = ranges_i[i], ranges_i[i+1]\n",
    "                        fields = torch.reshape(\n",
    "                            torch.sum(density[:, index_0:index_1], dim = 1), \n",
    "                            [self.n, self.n, self.n])\n",
    "                        fields_torch[i,j,:,:,:] = fields\n",
    "        return fields_torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set includes 8 pdbs with 4755 environments.\n",
      "Validation data setincludes 2 pdbs with 503 environments.\n"
     ]
    }
   ],
   "source": [
    "parsed_pdb_filenames = sorted(glob.glob(\"data/parsed/*coord*\"))\n",
    "random.shuffle(parsed_pdb_filenames)\n",
    "\n",
    "n_train_pdbs = int(len(parsed_pdb_filenames)*TRAIN_VAL_SPLIT)\n",
    "filenames_train = parsed_pdb_filenames[:n_train_pdbs]\n",
    "filenames_val = parsed_pdb_filenames[n_train_pdbs:]\n",
    "\n",
    "dataset_train = ResidueEnvironmentsDataset(filenames_train, transform=ToTensor())\n",
    "dataset_val = ResidueEnvironmentsDataset(filenames_val, transform=ToTensor())\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                              collate_fn=ToTensor.collate_cat, drop_last=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                            collate_fn=ToTensor.collate_cat, drop_last=True)\n",
    "\n",
    "print(f\"Training data set includes {len(filenames_train)} pdbs with \"\n",
    "      f\"{len(dataset_train)} environments.\")\n",
    "print(f\"Validation data setincludes {len(filenames_val)} pdbs with \"\n",
    "      f\"{len(dataset_val)} environments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1. Train loss: 2.235. Train Acc: 0.29. Val Acc: 0.06\n",
      "Epoch  2. Train loss: 1.309. Train Acc: 0.72. Val Acc: 0.24\n",
      "Epoch  3. Train loss: 0.780. Train Acc: 0.90. Val Acc: 0.23\n",
      "Epoch  4. Train loss: 0.417. Train Acc: 0.98. Val Acc: 0.23\n",
      "Epoch  5. Train loss: 0.220. Train Acc: 1.00. Val Acc: 0.22\n",
      "Epoch  6. Train loss: 0.120. Train Acc: 1.00. Val Acc: 0.23\n",
      "Epoch  7. Train loss: 0.074. Train Acc: 1.00. Val Acc: 0.23\n",
      "Epoch  8. Train loss: 0.053. Train Acc: 1.00. Val Acc: 0.23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ec56b9e67b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Take train step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mbatch_y_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcavity_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Exponential running mean for the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ec56b9e67b82>\u001b[0m in \u001b[0;36m_train_step\u001b[0;34m(cavity_model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcavity_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbatch_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcavity_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/miniconda3/envs/cavity-model/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-af7dfcb58136>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gaussian_blurring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-af7dfcb58136>\u001b[0m in \u001b[0;36m_gaussian_blurring\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m                     [\n\u001b[1;32m     86\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom_type_j_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchange_mask_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matom_type_j_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     ])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def _train_step(cavity_model: CavityModel, \n",
    "                optimizer: torch.optim.Adam, \n",
    "                loss_function: torch.nn.CrossEntropyLoss) -> (torch.Tensor, float):\n",
    "    cavity_model.train()\n",
    "    optimizer.zero_grad()    \n",
    "    batch_y_pred = cavity_model(batch_x)\n",
    "    loss_batch = loss_function(batch_y_pred, torch.argmax(batch_y, dim=-1))\n",
    "    loss_batch.backward()\n",
    "    optimizer.step()\n",
    "    return (batch_y_pred, loss_batch.detach().cpu().item())\n",
    "    \n",
    "\n",
    "# Define model\n",
    "cavity_model = CavityModel(DEVICE).to(DEVICE)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cavity_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train loop\n",
    "    loss_running_mean = 0.0\n",
    "    labels_true = []\n",
    "    labels_pred = []    \n",
    "    for batch_x, batch_y in dataloader_train:\n",
    "        # Take train step\n",
    "        batch_y_pred, loss_batch = _train_step(cavity_model, optimizer, loss_function)\n",
    "        \n",
    "        # Exponential running mean for the loss\n",
    "        loss_running_mean = loss_running_mean*0.9 + loss_batch*0.1\n",
    "        \n",
    "        labels_true.append(torch.argmax(batch_y, dim=-1).detach().cpu().numpy())\n",
    "        labels_pred.append(torch.argmax(batch_y_pred, dim=-1).detach().cpu().numpy())\n",
    "    acc_train = np.mean((np.reshape(labels_true, -1) == np.reshape(labels_pred, -1)))\n",
    "    \n",
    "    # Eval loop. Due to memory, we don't pass the whole data set\n",
    "    labels_true_val = []\n",
    "    labels_pred_val = []\n",
    "    for batch_x_val, batch_y_val in dataloader_val:\n",
    "        cavity_model.eval()\n",
    "        batch_y_pred_val = cavity_model(batch_x_val)\n",
    "        labels_true_val.append(torch.argmax(batch_y_val, dim=-1).detach().cpu().numpy())\n",
    "        labels_pred_val.append(torch.argmax(batch_y_pred_val, dim=-1).detach().cpu().numpy())\n",
    "    acc_val = np.mean((np.reshape(labels_true_val, -1) == np.reshape(labels_pred_val, -1)))\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d}. Train loss: {loss_running_mean:5.3f}. \"\n",
    "          f\"Train Acc: {acc_train:4.2f}. Val Acc: {acc_val:4.2f}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
